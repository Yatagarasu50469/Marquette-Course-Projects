{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#====================================================================\n",
    "#PROGRAM INFORMATION\n",
    "#====================================================================\n",
    "#PROGRAM NAME: Doggo_WGAN-GP\n",
    "#AUTHOR(S):         David Helminiak, EECE, Marquette University\n",
    "#\n",
    "#DATE CREATED:      April 2020\n",
    "#DATE MODIFIED:     May 2020\n",
    "#VERSION NUM:       1.0\n",
    "#DESCRIPTION:       Uses an optimized WGAN-GP model to generate\n",
    "#                   64x64 color images of dogs. \n",
    "#====================================================================\n",
    "\n",
    "import cv2 \n",
    "import glob\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import natsort\n",
    "import numpy as np\n",
    "import os\n",
    "import random\n",
    "import sys\n",
    "import shutil\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.layers import *\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.optimizers import *\n",
    "from PIL import Image\n",
    "from IPython.display import clear_output\n",
    "from IPython.core.debugger import Tracer\n",
    "\n",
    "#Establish GPU distribution strategy\n",
    "strategy = tf.distribute.MirroredStrategy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def makeGenerator():\n",
    "    \n",
    "    #Create a sequential NN model\n",
    "    model = Sequential()\n",
    "    \n",
    "    #8x8x512\n",
    "    model.add(Dense(8*8*512, input_shape=(randomNoiseSize,)))\n",
    "    model.add(LeakyReLU())\n",
    "    model.add(Reshape((8,8,512)))\n",
    "\n",
    "    #16x16x512\n",
    "    model.add(UpSampling2D(interpolation='nearest'))\n",
    "    model.add(Conv2D(512, (winSize, winSize), strides=(1,1), kernel_initializer='he_normal', padding='same'))\n",
    "    model.add(LayerNormalization(epsilon=epsilonValue))\n",
    "    model.add(LeakyReLU())\n",
    "    model.add(Conv2D(512, (winSize, winSize), strides=(1,1), kernel_initializer='he_normal', padding='same'))\n",
    "    model.add(LayerNormalization(epsilon=epsilonValue))\n",
    "    model.add(LeakyReLU())\n",
    "    \n",
    "    #32x32x256\n",
    "    model.add(UpSampling2D(interpolation='nearest'))\n",
    "    model.add(Conv2D(256, (winSize, winSize), strides=(1,1), kernel_initializer='he_normal', padding='same'))\n",
    "    model.add(LayerNormalization(epsilon=epsilonValue))\n",
    "    model.add(LeakyReLU())\n",
    "    model.add(Conv2D(256, (winSize, winSize), strides=(1,1), kernel_initializer='he_normal', padding='same'))\n",
    "    model.add(LayerNormalization(epsilon=epsilonValue))\n",
    "    model.add(LeakyReLU())\n",
    "    \n",
    "    #64x64x128\n",
    "    model.add(UpSampling2D(interpolation='nearest'))\n",
    "    model.add(Conv2D(128, (winSize, winSize), strides=(1,1), kernel_initializer='he_normal', padding='same'))\n",
    "    model.add(LayerNormalization(epsilon=epsilonValue))\n",
    "    model.add(LeakyReLU())\n",
    "    model.add(Conv2D(128, (winSize, winSize), strides=(1,1), kernel_initializer='he_normal', padding='same'))\n",
    "    model.add(LayerNormalization(epsilon=epsilonValue))\n",
    "    model.add(LeakyReLU())\n",
    "\n",
    "    #Activate\n",
    "    model.add(Conv2D(3, (winSize,winSize), strides=(1,1), kernel_initializer='he_normal', padding='same', activation='tanh'))\n",
    "    \n",
    "    return model\n",
    "    \n",
    "    \n",
    "def makeDiscriminator():\n",
    "    model = Sequential()\n",
    "    \n",
    "    #32x32x64  \n",
    "    model.add(Conv2D(64, (winSize,winSize), strides=(2,2), padding='same', input_shape=[outputSize, outputSize, numChannels], kernel_initializer='he_normal'))\n",
    "    model.add(LeakyReLU())\n",
    "    model.add(Conv2D(64, (winSize,winSize), strides=(1,1), padding='same', kernel_initializer='he_normal'))\n",
    "    model.add(LeakyReLU())\n",
    "    \n",
    "    #16x16x128\n",
    "    model.add(Conv2D(128, (winSize,winSize), strides=(2,2), padding='same', kernel_initializer='he_normal'))\n",
    "    model.add(LeakyReLU())\n",
    "    model.add(Conv2D(128, (winSize,winSize), strides=(1,1), padding='same', kernel_initializer='he_normal'))\n",
    "    model.add(LeakyReLU())\n",
    "\n",
    "    #8x8x256\n",
    "    model.add(Conv2D(256, (winSize,winSize), strides=(2,2), padding='same', kernel_initializer='he_normal'))\n",
    "    model.add(LeakyReLU())\n",
    "    model.add(Conv2D(256, (winSize,winSize), strides=(1,1), padding='same', kernel_initializer='he_normal'))\n",
    "    model.add(LeakyReLU())\n",
    "    \n",
    "    #4x4x512\n",
    "    model.add(Conv2D(512, (winSize,winSize), strides=(2,2), padding='same', kernel_initializer='he_normal'))\n",
    "    model.add(LeakyReLU())\n",
    "    model.add(Conv2D(512, (winSize,winSize), strides=(1,1), padding='same', kernel_initializer='he_normal'))\n",
    "    model.add(LeakyReLU())\n",
    "    \n",
    "    #Activate\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(1, kernel_initializer='he_normal'))\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#Define a training step\n",
    "def trainStep(images, trainGenFlag):\n",
    "\n",
    "    #Create some random noise to generate some fake images\n",
    "    noise = tf.random.normal([batchSize, randomNoiseSize], dtype=tf.float32)\n",
    "    \n",
    "    with tf.GradientTape() as genTape, tf.GradientTape() as disTape:\n",
    "\n",
    "        #Generate fake images with the generator\n",
    "        fakes = generator(noise, training=True)\n",
    "\n",
    "        #Add some noise to the real images\n",
    "        #realInputWithNoise = images + tf.random.normal(shape=tf.shape(images), mean=0.0, stddev=random.uniform(0.0, 0.1), dtype=tf.float32)\n",
    "\n",
    "        #Determine the discriminator results for the fake images\n",
    "        disFake = discriminator(fakes, training=True)\n",
    "\n",
    "        #Determine the discriminator results for the real images\n",
    "        disReal = discriminator(images, training=True)\n",
    "\n",
    "        #Determine the discriminator loss\n",
    "        disLoss = tf.reduce_mean(disFake) - tf.reduce_mean(disReal)\n",
    "\n",
    "        #Calculate and add the gradient penalty\n",
    "        alpha = tf.random.uniform([batchSize, 1, 1, 1], 0., 1.)\n",
    "        interpImage = images + (alpha * (fakes - images))\n",
    "        disInterp = discriminator(interpImage, training=True)\n",
    "        grad = tf.gradients(disInterp, [interpImage])[0]\n",
    "        slopes = tf.sqrt(tf.reduce_sum(tf.square(grad), axis=[1, 2, 3])+0.0)\n",
    "        gp = tf.reduce_mean((slopes - 1.)**2)\n",
    "        disLoss += gradientWeightPenalty * gp\n",
    "\n",
    "        #Caclulate the discriminator gradients\n",
    "        disGrad = disTape.gradient(disLoss, discriminator.trainable_variables)\n",
    "\n",
    "        #Use the gradients to optimize the discriminator\n",
    "        disOptimizer.apply_gradients(zip(disGrad, discriminator.trainable_variables))\n",
    "\n",
    "        #If this step the generator should also be trained\n",
    "        if trainGenFlag: \n",
    "\n",
    "            #Determine the generator loss\n",
    "            genLoss = -1. * tf.reduce_mean(disFake)\n",
    "\n",
    "            #Caclulate the generator gradients\n",
    "            genGrad = genTape.gradient(genLoss, generator.trainable_variables)\n",
    "\n",
    "            #Use the gradients to optimize the generator\n",
    "            genOptimizer.apply_gradients(zip(genGrad, generator.trainable_variables))\n",
    "\n",
    "            return [genLoss, disLoss]\n",
    "        else:\n",
    "            return disLoss\n",
    "\n",
    "#Define execution of training step given the system computational scope\n",
    "@tf.function\n",
    "def distributed_train_step(images, trainGenFlag):\n",
    "    if trainGenFlag:\n",
    "        genLosses, disLosses = strategy.run(trainStep, args=(images, trainGenFlag,))\n",
    "        return [strategy.reduce(tf.distribute.ReduceOp.MEAN, genLosses, axis=None), \n",
    "                strategy.reduce(tf.distribute.ReduceOp.MEAN, disLosses, axis=None)]\n",
    "    else:\n",
    "        disLosses = strategy.run(trainStep, args=(images, trainGenFlag,))\n",
    "        return strategy.reduce(tf.distribute.ReduceOp.MEAN, disLosses, axis=None)\n",
    "\n",
    "#Define the training procedure\n",
    "def train(dataset, numEpochs):\n",
    "    results = []\n",
    "    bestDisLoss = np.nan\n",
    "    bestGenerator = np.nan\n",
    "    bestDiscriminator = np.nan\n",
    "    epochsSinceImproved = 0\n",
    "    for epoch in range(numEpochs):\n",
    "        \n",
    "        batchDisResults = []\n",
    "        batchGenResults = []\n",
    "        trainIter = trainGenRate-1\n",
    "        for batch in dataset:\n",
    "            trainIter+=1\n",
    "            if trainIter >= trainGenRate:\n",
    "                result = distributed_train_step(batch, True) \n",
    "                batchGenResults.append(result[0].numpy())\n",
    "                batchDisResults.append(result[1].numpy())\n",
    "                trainIter = 0\n",
    "            else:\n",
    "                result = distributed_train_step(batch, False) \n",
    "                batchDisResults.append(result.numpy())\n",
    "            \n",
    "        results.append([np.mean(batchGenResults), np.mean(batchDisResults)])\n",
    "        \n",
    "        #Wipe the screen of prior outputs\n",
    "        clear_output()\n",
    "        \n",
    "        #Generate fake images using consistent randomly chosen seeds\n",
    "        fakeImages = tf.reshape(generator(seed, training=False), shape=(4, outputSize,outputSize,numChannels))\n",
    "        \n",
    "        #Plot losses and fake images\n",
    "        f = plt.figure(figsize=(20,10))\n",
    "        f.subplots_adjust(top = 0.85)\n",
    "        f.subplots_adjust(wspace=0.2, hspace=0.2)\n",
    "        plt.suptitle('Epoch:'+str(epoch), fontsize=20, fontweight='bold', y = 0.95)\n",
    "\n",
    "        ax1 = plt.subplot2grid((2,4), (0,0), colspan=2)\n",
    "        ax1.plot(np.asarray(results)[:,0])\n",
    "        ax1.set_title('Generator Loss: ' + str(np.mean(batchGenResults)), fontsize=15, fontweight='bold')\n",
    "\n",
    "        ax2 = plt.subplot2grid((2,4), (1,0), colspan=2)\n",
    "        ax2.plot(np.asarray(results)[:,1])\n",
    "        ax2.set_title('Discriminator Loss: '+ str(np.mean(batchDisResults)), fontsize=15, fontweight='bold')\n",
    "        \n",
    "        ax3 = plt.subplot2grid((2,4), (0,2))\n",
    "        ax3.imshow(((fakeImages[0] * 127.5 + 127.5) / 255.).numpy())\n",
    "\n",
    "        ax4 = plt.subplot2grid((2,4), (0,3))\n",
    "        ax4.imshow(((fakeImages[1] * 127.5 + 127.5) / 255.).numpy())\n",
    "\n",
    "        ax5 = plt.subplot2grid((2,4), (1,2))\n",
    "        ax5.imshow(((fakeImages[2] * 127.5 + 127.5) / 255.).numpy())\n",
    "\n",
    "        ax6 = plt.subplot2grid((2,4), (1,3))\n",
    "        ax6.imshow(((fakeImages[3] * 127.5 + 127.5) / 255.).numpy())\n",
    "        plt.show()\n",
    "        \n",
    "        #Check epoch number, save loss/fake image information\n",
    "        if (epoch%1) == 0: f.savefig(dir_output + '/' + str(epoch) + '_epoches.png', bbox_inches='tight')\n",
    "        \n",
    "        #Check epoch number\n",
    "        if (epoch%50) == 0:\n",
    "            #Save model checkpoint\n",
    "            dir_checkpointSave = dir_checkpoint+'/checkpoint-'+str(epoch)+'/'\n",
    "            os.makedirs(dir_checkpointSave)\n",
    "            checkpoint.save(file_prefix = dir_checkpointSave)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#USER PARAMETERS\n",
    "#===========================================================\n",
    "\n",
    "#Should the modelbe trained, or loaded from prior run\n",
    "trainModel = True\n",
    "\n",
    "#If loading a prior run, which epoch should be loaded; runs that don't exist will not restore a model\n",
    "restoreEpochNum = -1\n",
    "\n",
    "#Define the initial learning rate for the optimizer\n",
    "disLearningRate=1e-4\n",
    "genLearningRate=1e-4\n",
    "\n",
    "#How often (batch iterations) should the generator be trained\n",
    "trainGenRate = 5\n",
    "\n",
    "#Define the number of samples fed through each step\n",
    "batchSize = 8\n",
    "gBatchSize = batchSize * strategy.num_replicas_in_sync\n",
    "\n",
    "#How many epochs should be run at minimum\n",
    "numEpochs = 10000\n",
    "\n",
    "#Specify the output/input image size\n",
    "outputSize = 2**6\n",
    "\n",
    "#Specify the number of output/input channels\n",
    "numChannels = 3\n",
    "\n",
    "#Specify the convolution window size; #columns, #rows\n",
    "winSize = 3\n",
    "\n",
    "#Specify the stride length\n",
    "strideSize = 2\n",
    "\n",
    "#Number of convolutional layers for the generator and discriminator\n",
    "numConv = 4\n",
    "\n",
    "#Length of the random noise vector; made to correspond with max number of channels in the generator\n",
    "randomNoiseSize = 128\n",
    "\n",
    "epsilonValue = 0.00001\n",
    "gradientWeightPenalty = 10\n",
    "\n",
    "#STATIC PARAMETERS\n",
    "#===========================================================\n",
    "#Output directory\n",
    "dir_output = './Results'\n",
    "\n",
    "#Output directory for final generated images\n",
    "dir_genOutput = './Generated'\n",
    "\n",
    "#Checkpoint directory\n",
    "dir_checkpoint = './Checkpoints'\n",
    "\n",
    "#Training data directory\n",
    "#dir_trainData = './Training_Anime/'\n",
    "#dir_trainData = './Training_Pokemon/'\n",
    "dir_trainData = './Training_Doggos/'\n",
    "\n",
    "#Testing data directory\n",
    "#dir_testData = './Testing_Data/'\n",
    "\n",
    "#Clear output and checkpoint directories\n",
    "if os.path.exists(dir_output): shutil.rmtree(dir_output)\n",
    "os.makedirs(dir_output)\n",
    "\n",
    "if os.path.exists(dir_genOutput): shutil.rmtree(dir_genOutput)\n",
    "os.makedirs(dir_genOutput)\n",
    "\n",
    "if os.path.exists(dir_checkpoint) and trainModel: \n",
    "    shutil.rmtree(dir_checkpoint)\n",
    "    os.makedirs(dir_checkpoint)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "\n",
    "#MAIN CODE EXECUTION\n",
    "#===========================================================\n",
    "\n",
    "#print('Loading Data')\n",
    "#(train_images, train_labels), (_, _) = tf.keras.datasets.mnist.load_data()\n",
    "#train_images = np.asarray([cv2.resize(img,(int(outputSize),int(outputSize))) for img in train_images])\n",
    "#train_images = train_images.reshape(train_images.shape[0], train_images.shape[1], train_images.shape[2], 1)\n",
    "#train_images = (train_images - 127.5) / 127.5\n",
    "#trainData = tf.data.Dataset.from_tensor_slices(train_images).shuffle(len(train_images)).batch(batchSize)\n",
    "if trainModel:\n",
    "    \n",
    "    #Inform user\n",
    "    print('Loading Training Data')\n",
    "\n",
    "    #Load in training data\n",
    "    #trainImages = np.asarray([cv2.resize(cv2.imread(imageFileName, -1),(int(outputSize),int(outputSize))) for imageFileName in glob.glob(dir_trainData + '/*.png')])\n",
    "    trainImages = np.asarray([np.asarray(Image.open(imageFileName).convert('RGB').resize((int(outputSize),int(outputSize)))) for imageFileName in glob.glob(dir_trainData + '/*.png')])\n",
    "    #Save the number of training images\n",
    "    numTraining = len(trainImages)\n",
    "\n",
    "    #Images should be normalized to be between -1 and 1 for visualization and match with noise input\n",
    "    trainImages = (trainImages-127.5)/127.5\n",
    "    trainImages = trainImages.astype('float32')\n",
    "\n",
    "    #Setup tensors from the training data for input into the network\n",
    "    trainImages = trainImages.reshape(trainImages.shape[0], trainImages.shape[1], trainImages.shape[2], trainImages.shape[3])\n",
    "    trainData = tf.data.Dataset.from_tensor_slices(trainImages)\n",
    "\n",
    "    #Shuffle and batch the training data\n",
    "    trainData = trainData.shuffle(numTraining).batch(gBatchSize, drop_remainder=True)\n",
    "    \n",
    "    #Prepare the data for distribution across multiple GPUs\n",
    "    trainData = strategy.experimental_distribute_dataset(trainData)\n",
    "\n",
    "#Define cross entropy metrics\n",
    "#0.2: 0.1 for False and 0.9 for True\n",
    "#0.3: 0.2 0.8\n",
    "#0.4: 0.3 0.7\n",
    "#label_smoothing=0.1\n",
    "#disc_crossEntropy = keras.losses.BinaryCrossentropy(from_logits = False)\n",
    "#gen_crossEntropy = keras.losses.BinaryCrossentropy(from_logits = False)\n",
    "\n",
    "#Spcify the optimizers for the generator and discriminator networks\n",
    "#genOptimizer = RMSprop(learning_rate=genLearningRate, rho=0.9)\n",
    "#disOptimizer = RMSprop(learning_rate=disLearningRate, rho=0.9)\n",
    "\n",
    "#genOptimizer = Adam(learning_rate=genLearningRate, beta_1=0.5)\n",
    "#disOptimizer = Adam(learning_rate=disLearningRate, beta_1=0.5)\n",
    "with strategy.scope():\n",
    "    genOptimizer = Nadam(learning_rate=genLearningRate, beta_1=0.5, beta_2=0.9)\n",
    "    disOptimizer = Nadam(learning_rate=disLearningRate, beta_1=0.5, beta_2=0.9)\n",
    "\n",
    "#Create a random seed for noise generation\n",
    "seed = tf.random.normal([4, randomNoiseSize], dtype=tf.float32)\n",
    "\n",
    "#Create a discriminator\n",
    "print(\"Creating a discriminator\")\n",
    "with strategy.scope(): discriminator = makeDiscriminator()\n",
    "\n",
    "#Create a generator\n",
    "print(\"Creating a generator\")\n",
    "with strategy.scope(): generator = makeGenerator()\n",
    "\n",
    "#Create a checkpoint object\n",
    "with strategy.scope(): checkpoint = tf.train.Checkpoint(generator_optimizer=genOptimizer, discriminator_optimizer=disOptimizer, generator=generator, discriminator=discriminator)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#Print out generator structure\n",
    "generator.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Print out discriminator structure\n",
    "discriminator.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "\n",
    "#If training the model from scratch\n",
    "if trainModel:\n",
    "    \n",
    "    #Inform user\n",
    "    print('Building and training model')\n",
    "    \n",
    "    #Use GPU to perform training\n",
    "    errCode = train(trainData, numEpochs)\n",
    "\n",
    "#If just loading a prior model\n",
    "else: \n",
    "    \n",
    "    #Inform user\n",
    "    print('Loading prior model')\n",
    "    \n",
    "    #Restore specfied checkpoint\n",
    "    checkpoint.restore(tf.train.latest_checkpoint(dir_checkpoint+'/checkpoint-'+str(restoreEpochNum)+'/'))\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Randomly generate a a bunch of doggos, use the discriminator to verify that they are indeed dogs\n",
    "\n",
    "restoreEpochNum = 5000\n",
    "checkpoint.restore(tf.train.latest_checkpoint(dir_checkpoint+'/checkpoint-'+str(restoreEpochNum)+'/'))\n",
    "checkpoint.restore(tf.train.latest_checkpoint(dir_checkpoint))\n",
    "\n",
    "#Inform user\n",
    "print('Generating Some New Images')\n",
    "\n",
    "#Loop until completion\n",
    "imSaved = 0\n",
    "while True:\n",
    "    \n",
    "    #Create a new fake image\n",
    "    truncation = 1  # Truncation trick, can trade fidelity for variation [0-low variation, 1-max variation]\n",
    "    seed = truncation * tf.random.truncated_normal(shape = [1, randomNoiseSize], dtype=tf.float32)\n",
    "    fakeImage = tf.reshape(generator(seed, training=False), shape=(outputSize,outputSize,numChannels))\n",
    "    \n",
    "    #Query the discriminator\n",
    "    discrimResult = discriminator(fakeImage.numpy().reshape(1, outputSize, outputSize, numChannels), training=False).numpy()[0][0]\n",
    "    \n",
    "    #If the discriminator was sufficiently fooled, save the image\n",
    "    imSaved+=1\n",
    "    fakeImage = ((fakeImage * 127.5 + 127.5) / 255.).numpy()\n",
    "    fakeImage = (255.0 / np.max(fakeImage) * (fakeImage - np.min(fakeImage))).astype(np.uint8)\n",
    "\n",
    "    im = Image.fromarray(fakeImage)\n",
    "    im.save(dir_genOutput + '/' + 'genImage_'+str(imSaved)+'_score'+str(discrimResult)+'.png')\n",
    "    if imSaved == 200: break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
