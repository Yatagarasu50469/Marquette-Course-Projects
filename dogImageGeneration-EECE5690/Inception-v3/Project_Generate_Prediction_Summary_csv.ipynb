{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_files       \n",
    "from keras.utils import np_utils\n",
    "import numpy as np\n",
    "from glob import glob\n",
    "import os\n",
    "import numpy as np\n",
    "from keras.callbacks import ModelCheckpoint  \n",
    "from keras.layers import Conv2D, MaxPooling2D, GlobalAveragePooling2D, AveragePooling2D\n",
    "from keras.layers import Dropout, Flatten, Dense\n",
    "from keras.models import Sequential\n",
    "\n",
    "from keras.preprocessing import image                  \n",
    "\n",
    "from keras.applications.resnet50 import preprocess_input, decode_predictions\n",
    "from keras import regularizers\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_dataset(path):\n",
    "    data = load_files(path)\n",
    "    dog_files = np.array(data['filenames'])\n",
    "    dog_targets = np_utils.to_categorical(np.array(data['target']), 133)\n",
    "    return dog_files, dog_targets\n",
    "\n",
    "train_files, train_targets = load_dataset('dogImages/train')\n",
    "valid_files, valid_targets = load_dataset('dogImages/valid')\n",
    "test_files, test_targets = load_dataset('dogImages/test')\n",
    "\n",
    "dog_names = [item[20:-1] for item in sorted(glob(\"dogImages/train/*/\"))]\n",
    "dog_breeds = len(dog_names)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_width, img_height = 224, 224\n",
    "\n",
    "def path_to_tensor(img_path):\n",
    "    img = image.load_img(img_path, target_size=(img_width, img_height))\n",
    "    x = image.img_to_array(img)\n",
    "    return np.expand_dims(x, axis=0)\n",
    "\n",
    "def paths_to_tensor(img_paths):\n",
    "    list_of_tensors = [path_to_tensor(img_path) for img_path in tqdm(img_paths)]\n",
    "    return np.vstack(list_of_tensors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ResNet50_predict_labels(img_path):\n",
    "\n",
    "    img = preprocess_input(path_to_tensor(img_path))\n",
    "    return np.argmax(ResNet50_model.predict(img))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dog_detector(img_path):\n",
    "    prediction = ResNet50_predict_labels(img_path)\n",
    "    return ((prediction <= 268) & (prediction >= 151)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "bottleneck_features = np.load('bottleneck_features/DogInceptionV3Data.npz')\n",
    "train_InceptionV3   = bottleneck_features['train']\n",
    "valid_InceptionV3   = bottleneck_features['valid']\n",
    "test_InceptionV3    = bottleneck_features['test']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "inception_model = Sequential()\n",
    "inception_model.add(GlobalAveragePooling2D(input_shape=train_InceptionV3.shape[1:]))\n",
    "inception_model.add(Dense(150, activation='relu', kernel_regularizer=regularizers.l2(0.005)))\n",
    "inception_model.add(Dropout(0.4))\n",
    "inception_model.add(Dense(dog_breeds, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "inception_model.compile(loss='categorical_crossentropy', optimizer='rmsprop', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "inception_model.load_weights('saved_models/weights.best.InceptionV3.hdf5')\n",
    "from keras.applications.inception_v3 import InceptionV3, preprocess_input\n",
    "import matplotlib.image as mpimg\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "myModel = InceptionV3(weights='imagenet', include_top=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# myModel = InceptionV3(weights='imagenet', include_top=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def extract_InceptionV3(tensor):\n",
    "    \n",
    "#     return myModel.predict(preprocess_input(tensor))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_N = 4\n",
    "\n",
    "def predict_breed(path):\n",
    "    image_tensor = path_to_tensor(path)\n",
    "    bottleneck_features = myModel.predict(preprocess_input(image_tensor))\n",
    "    prediction = inception_model.predict(bottleneck_features)[0]\n",
    "    breeds_predicted = [dog_names[idx] for idx in np.argsort(prediction)[::-1][:top_N]]\n",
    "    confidence_predicted = np.sort(prediction)[::-1][:top_N]\n",
    "    return breeds_predicted, confidence_predicted\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_prediction(path, multiple_breeds = False):\n",
    "    breeds, confidence = predict_breed(path)\n",
    "    img = mpimg.imread(path)\n",
    "    plt.axis('off')\n",
    "\n",
    "\n",
    "    if multiple_breeds:\n",
    "        all_labs   = []\n",
    "        all_scores = []\n",
    "        for i, j in zip(breeds, confidence):\n",
    "#             print(i.replace(\"_\", \" \"))\n",
    "            all_labs.append(i.replace(\"_\", \" \"))\n",
    "            all_scores.append(j)\n",
    "    \n",
    "    return all_labs, all_scores\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 200/200 [00:05<00:00, 38.54it/s]\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAV0AAADnCAYAAAC9roUQAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjMsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+AADFEAAADKUlEQVR4nO3UMQEAIAzAMMC/5+GiHCQKenXPzAKgcV4HAPzEdAFCpgsQMl2AkOkChEwXIGS6ACHTBQiZLkDIdAFCpgsQMl2AkOkChEwXIGS6ACHTBQiZLkDIdAFCpgsQMl2AkOkChEwXIGS6ACHTBQiZLkDIdAFCpgsQMl2AkOkChEwXIGS6ACHTBQiZLkDIdAFCpgsQMl2AkOkChEwXIGS6ACHTBQiZLkDIdAFCpgsQMl2AkOkChEwXIGS6ACHTBQiZLkDIdAFCpgsQMl2AkOkChEwXIGS6ACHTBQiZLkDIdAFCpgsQMl2AkOkChEwXIGS6ACHTBQiZLkDIdAFCpgsQMl2AkOkChEwXIGS6ACHTBQiZLkDIdAFCpgsQMl2AkOkChEwXIGS6ACHTBQiZLkDIdAFCpgsQMl2AkOkChEwXIGS6ACHTBQiZLkDIdAFCpgsQMl2AkOkChEwXIGS6ACHTBQiZLkDIdAFCpgsQMl2AkOkChEwXIGS6ACHTBQiZLkDIdAFCpgsQMl2AkOkChEwXIGS6ACHTBQiZLkDIdAFCpgsQMl2AkOkChEwXIGS6ACHTBQiZLkDIdAFCpgsQMl2AkOkChEwXIGS6ACHTBQiZLkDIdAFCpgsQMl2AkOkChEwXIGS6ACHTBQiZLkDIdAFCpgsQMl2AkOkChEwXIGS6ACHTBQiZLkDIdAFCpgsQMl2AkOkChEwXIGS6ACHTBQiZLkDIdAFCpgsQMl2AkOkChEwXIGS6ACHTBQiZLkDIdAFCpgsQMl2AkOkChEwXIGS6ACHTBQiZLkDIdAFCpgsQMl2AkOkChEwXIGS6ACHTBQiZLkDIdAFCpgsQMl2AkOkChEwXIGS6ACHTBQiZLkDIdAFCpgsQMl2AkOkChEwXIGS6ACHTBQiZLkDIdAFCpgsQMl2AkOkChEwXIGS6ACHTBQiZLkDIdAFCpgsQMl2AkOkChEwXIGS6ACHTBQiZLkDIdAFCpgsQMl2AkOkChEwXIGS6ACHTBQiZLkDIdAFCpgsQMl2AkOkChEwXIGS6ACHTBQiZLkDIdAFCpgsQMl2AkOkChEwXIHQBcjcEy3+fc28AAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "srcDir        = 'L_batchSize8_training_epoch5000_truncatedNormal'\n",
    "\n",
    "allFiles      = os.listdir(srcDir)\n",
    "random.shuffle(allFiles) \n",
    "all_fName     = []\n",
    "all_A_name    = []\n",
    "all_A_score   = []\n",
    "all_B_name    = []\n",
    "all_B_score   = []\n",
    "all_C_name    = []\n",
    "all_C_score   = []\n",
    "all_D_name    = []\n",
    "all_D_score   = []\n",
    "all_Models    = []\n",
    "\n",
    "cntr = 0\n",
    "for thisFname in tqdm(allFiles):\n",
    "    if thisFname.endswith('.png'):\n",
    "#         if cntr >1:\n",
    "#             break\n",
    "        all_labs, all_scores = make_prediction(srcDir + os.sep + thisFname, multiple_breeds = True)\n",
    "        all_fName.append(thisFname)\n",
    "        all_A_name.append(all_labs[0])\n",
    "        all_B_name.append(all_labs[1])\n",
    "        all_C_name.append(all_labs[2])\n",
    "        all_D_name.append(all_labs[3])\n",
    "\n",
    "        all_A_score.append(all_scores[0])\n",
    "        all_B_score.append(all_scores[1])\n",
    "        all_C_score.append(all_scores[2])\n",
    "        all_D_score.append(all_scores[3])\n",
    "        all_Models.append('GAN_v1')\n",
    "        cntr += 1\n",
    "\n",
    "D_df = pd.DataFrame()\n",
    "\n",
    "D_df['Model']        = all_Models\n",
    "D_df['FName']        = all_fName\n",
    "D_df['all_A_name']   = all_A_name\n",
    "D_df['all_A_score']  = all_A_score\n",
    "D_df['all_B_name']   = all_B_name\n",
    "D_df['all_B_score']  = all_B_score\n",
    "D_df['all_C_name']   = all_C_name\n",
    "D_df['all_C_score']  = all_C_score\n",
    "D_df['all_D_name']   = all_D_name\n",
    "D_df['all_D_score']  = all_D_score\n",
    "\n",
    "D_df.to_csv('L_batchSize8_training_epoch5000_truncatedNormal.csv',index=False) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.2922598133049905"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(D_df['all_A_score'].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "srcDir        = 'S_Results_v2'\n",
    "\n",
    "allFiles      = os.listdir(srcDir)\n",
    "random.shuffle(allFiles) \n",
    "all_fName     = []\n",
    "all_A_name    = []\n",
    "all_A_score   = []\n",
    "all_B_name    = []\n",
    "all_B_score   = []\n",
    "all_C_name    = []\n",
    "all_C_score   = []\n",
    "all_D_name    = []\n",
    "all_D_score   = []\n",
    "all_Models    = []\n",
    "\n",
    "cntr = 0\n",
    "for thisFname in tqdm(allFiles):\n",
    "    if thisFname.endswith('.png'):\n",
    "#         if cntr >1:\n",
    "#             break\n",
    "        all_labs, all_scores = make_prediction(srcDir + os.sep + thisFname, multiple_breeds = True)\n",
    "        all_fName.append(thisFname)\n",
    "        all_A_name.append(all_labs[0])\n",
    "        all_B_name.append(all_labs[1])\n",
    "        all_C_name.append(all_labs[2])\n",
    "        all_D_name.append(all_labs[3])\n",
    "\n",
    "        all_A_score.append(all_scores[0])\n",
    "        all_B_score.append(all_scores[1])\n",
    "        all_C_score.append(all_scores[2])\n",
    "        all_D_score.append(all_scores[3])\n",
    "        all_Models.append('CVAE_v1')\n",
    "        cntr += 1\n",
    "\n",
    "S_df = pd.DataFrame()\n",
    "\n",
    "S_df['Model']        = all_Models\n",
    "S_df['FName']        = all_fName\n",
    "S_df['all_A_name']   = all_A_name\n",
    "S_df['all_A_score']  = all_A_score\n",
    "S_df['all_B_name']   = all_B_name\n",
    "S_df['all_B_score']  = all_B_score\n",
    "S_df['all_C_name']   = all_C_name\n",
    "S_df['all_C_score']  = all_C_score\n",
    "S_df['all_D_name']   = all_D_name\n",
    "S_df['all_D_score']  = all_D_score\n",
    "\n",
    "S_df.to_excel('CVAE_v2.xlsx',index=False) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean(S_df['all_A_score'].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "srcDir        = 'D_Training'\n",
    "\n",
    "allFiles      = os.listdir(srcDir)\n",
    "random.shuffle(allFiles) \n",
    "all_fName     = []\n",
    "all_A_name    = []\n",
    "all_A_score   = []\n",
    "all_B_name    = []\n",
    "all_B_score   = []\n",
    "all_C_name    = []\n",
    "all_C_score   = []\n",
    "all_D_name    = []\n",
    "all_D_score   = []\n",
    "all_Models    = []\n",
    "\n",
    "cntr = 0\n",
    "for thisFname in tqdm(allFiles):\n",
    "    if thisFname.endswith('.png'):\n",
    "#         if cntr >1:\n",
    "#             break\n",
    "        all_labs, all_scores = make_prediction(srcDir + os.sep + thisFname, multiple_breeds = True)\n",
    "        all_fName.append(thisFname)\n",
    "        all_A_name.append(all_labs[0])\n",
    "        all_B_name.append(all_labs[1])\n",
    "        all_C_name.append(all_labs[2])\n",
    "        all_D_name.append(all_labs[3])\n",
    "\n",
    "        all_A_score.append(all_scores[0])\n",
    "        all_B_score.append(all_scores[1])\n",
    "        all_C_score.append(all_scores[2])\n",
    "        all_D_score.append(all_scores[3])\n",
    "        all_Models.append('GAN_Train_Set')\n",
    "        cntr += 1\n",
    "\n",
    "DT_df = pd.DataFrame()\n",
    "\n",
    "DT_df['Model']        = all_Models\n",
    "DT_df['FName']        = all_fName\n",
    "DT_df['all_A_name']   = all_A_name\n",
    "DT_df['all_A_score']  = all_A_score\n",
    "DT_df['all_B_name']   = all_B_name\n",
    "DT_df['all_B_score']  = all_B_score\n",
    "DT_df['all_C_name']   = all_C_name\n",
    "DT_df['all_C_score']  = all_C_score\n",
    "DT_df['all_D_name']   = all_D_name\n",
    "DT_df['all_D_score']  = all_D_score\n",
    "\n",
    "DT_df.to_excel('GAN_Train.xlsx',index=False) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean(DT_df['all_A_score'].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "srcDir        = 'S_Training'\n",
    "\n",
    "allFiles      = os.listdir(srcDir)\n",
    "random.shuffle(allFiles) \n",
    "all_fName     = []\n",
    "all_A_name    = []\n",
    "all_A_score   = []\n",
    "all_B_name    = []\n",
    "all_B_score   = []\n",
    "all_C_name    = []\n",
    "all_C_score   = []\n",
    "all_D_name    = []\n",
    "all_D_score   = []\n",
    "all_Models    = []\n",
    "\n",
    "cntr = 0\n",
    "for thisFname in tqdm(allFiles):\n",
    "    if thisFname.endswith('.png'):\n",
    "#         if cntr >1:\n",
    "#             break\n",
    "        all_labs, all_scores = make_prediction(srcDir + os.sep + thisFname, multiple_breeds = True)\n",
    "        all_fName.append(thisFname)\n",
    "        all_A_name.append(all_labs[0])\n",
    "        all_B_name.append(all_labs[1])\n",
    "        all_C_name.append(all_labs[2])\n",
    "        all_D_name.append(all_labs[3])\n",
    "\n",
    "        all_A_score.append(all_scores[0])\n",
    "        all_B_score.append(all_scores[1])\n",
    "        all_C_score.append(all_scores[2])\n",
    "        all_D_score.append(all_scores[3])\n",
    "        all_Models.append('CVAE_Train_Set')\n",
    "        cntr += 1\n",
    "\n",
    "ST_df = pd.DataFrame()\n",
    "\n",
    "ST_df['Model']        = all_Models\n",
    "ST_df['FName']        = all_fName\n",
    "ST_df['all_A_name']   = all_A_name\n",
    "ST_df['all_A_score']  = all_A_score\n",
    "ST_df['all_B_name']   = all_B_name\n",
    "ST_df['all_B_score']  = all_B_score\n",
    "ST_df['all_C_name']   = all_C_name\n",
    "ST_df['all_C_score']  = all_C_score\n",
    "ST_df['all_D_name']   = all_D_name\n",
    "ST_df['all_D_score']  = all_D_score\n",
    "\n",
    "ST_df.to_excel('CVAE_Train.xlsx',index=False) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ST_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean(ST_df['all_A_score'].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "srcDir        = 'Val_Results'\n",
    "\n",
    "allFiles      = os.listdir(srcDir)\n",
    "random.shuffle(allFiles) \n",
    "all_fName     = []\n",
    "all_A_name    = []\n",
    "all_A_score   = []\n",
    "all_B_name    = []\n",
    "all_B_score   = []\n",
    "all_C_name    = []\n",
    "all_C_score   = []\n",
    "all_D_name    = []\n",
    "all_D_score   = []\n",
    "all_Models    = []\n",
    "\n",
    "cntr = 0\n",
    "for thisFname in tqdm(allFiles):\n",
    "    if thisFname.endswith('.jpg'):\n",
    "#         if cntr >1:\n",
    "#             break\n",
    "        all_labs, all_scores = make_prediction(srcDir + os.sep + thisFname, multiple_breeds = True)\n",
    "        all_fName.append(thisFname)\n",
    "        all_A_name.append(all_labs[0])\n",
    "        all_B_name.append(all_labs[1])\n",
    "        all_C_name.append(all_labs[2])\n",
    "        all_D_name.append(all_labs[3])\n",
    "\n",
    "        all_A_score.append(all_scores[0])\n",
    "        all_B_score.append(all_scores[1])\n",
    "        all_C_score.append(all_scores[2])\n",
    "        all_D_score.append(all_scores[3])\n",
    "        all_Models.append('GAN_v2')\n",
    "        cntr += 1\n",
    "\n",
    "ST_df = pd.DataFrame()\n",
    "\n",
    "ST_df['Model']        = all_Models\n",
    "ST_df['FName']        = all_fName\n",
    "ST_df['all_A_name']   = all_A_name\n",
    "ST_df['all_A_score']  = all_A_score\n",
    "ST_df['all_B_name']   = all_B_name\n",
    "ST_df['all_B_score']  = all_B_score\n",
    "ST_df['all_C_name']   = all_C_name\n",
    "ST_df['all_C_score']  = all_C_score\n",
    "ST_df['all_D_name']   = all_D_name\n",
    "ST_df['all_D_score']  = all_D_score\n",
    "\n",
    "ST_df.to_excel('Val_Results.xlsx',index=False) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean(ST_df['all_A_score'].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
